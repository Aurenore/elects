{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test daily_earlyrnn model\n",
    "Test the new model to check if it is working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os \n",
    "#os.environ['MPLCONFIGDIR'] = \"$HOME\"\n",
    "#os.envir\n",
    "# on[\"WANDB_DIR\"] = os.path.join(os.path.dirname(__file__), \"..\", \"wandb\")\n",
    "# sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), os.path.pardir)))\n",
    "# sys append \n",
    "sys.path.append(\"..\")\n",
    "from data import BavarianCrops, BreizhCrops, SustainbenchCrops, ModisCDL\n",
    "from torch.utils.data import DataLoader\n",
    "from models.earlyrnn import EarlyRNN\n",
    "from models.daily_earlyrnn import DailyEarlyRNN\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from utils.losses.early_reward_loss import EarlyRewardLoss\n",
    "from utils.losses.stopping_time_proximity_loss import StoppingTimeProximityLoss, sample_three_uniform_numbers\n",
    "import sklearn.metrics\n",
    "import pandas as pd\n",
    "import wandb\n",
    "from utils.plots import plot_label_distribution_datasets, boxplot_stopping_times\n",
    "from utils.doy import get_doys_dict_test, get_doy_stop, create_sorted_doys_dict_test, get_approximated_doys_dict\n",
    "from utils.helpers_training import parse_args_sweep, train_epoch\n",
    "from utils.helpers_testing import test_epoch\n",
    "from utils.metrics import harmonic_mean_score\n",
    "from models.model_helpers import count_parameters\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config \n",
    "class Config():\n",
    "    def __init__(self):\n",
    "        self.alpha = 0.6\n",
    "        self.backbonemodel = \"LSTM\"\n",
    "        self.batchsize = 256\n",
    "        self.corrected = True\n",
    "        self.dataroot = os.path.join(os.environ.get(\"HOME\", os.environ.get(\"USERPROFILE\")),\"elects_data\")\n",
    "        self.dataset = \"breizhcrops\"\n",
    "        self.device = \"cuda\"\n",
    "        self.epochs = 100\n",
    "        self.epsilon = 10\n",
    "        self.extra_padding_list = [0]\n",
    "        self.hidden_dims = 64\n",
    "        self.learning_rate = 0.001\n",
    "        self.loss_weight = \"balanced\"\n",
    "        self.patience = 30\n",
    "        self.resume = False\n",
    "        self.sequencelength = 365\n",
    "        self.validation_set = \"valid\"\n",
    "        self.weight_decay = 0\n",
    "        self.daily_timestamps = True\n",
    "        self.original_time_serie_lengths = [102]\n",
    "        self.loss = \"stopping_time_proximity\"\n",
    "        \n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2559635960 2559635960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading data into RAM: 100%|██████████| 67523/67523 [00:28<00:00, 2330.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2253658856 2253658856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading data into RAM: 100%|██████████| 85310/85310 [00:34<00:00, 2485.60it/s]\n"
     ]
    }
   ],
   "source": [
    "dataroot = os.path.join(config.dataroot,\"breizhcrops\")\n",
    "nclasses = 9\n",
    "input_dim = 13\n",
    "test_ds = BreizhCrops(root=dataroot,partition=config.validation_set, sequencelength=config.sequencelength, corrected=config.corrected, daily_timestamps=config.daily_timestamps, original_time_serie_lengths=config.original_time_serie_lengths)\n",
    "train_ds = BreizhCrops(root=dataroot,partition=\"train\", sequencelength=config.sequencelength, corrected=config.corrected, daily_timestamps=config.daily_timestamps, original_time_serie_lengths=config.original_time_serie_lengths)\n",
    "traindataloader = DataLoader(train_ds,batch_size=config.batchsize)\n",
    "testdataloader = DataLoader(test_ds, batch_size=config.batchsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cost function: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alphas: 0.1693766564130783, 0.12460131198167801, 0.7060220837593079\n"
     ]
    }
   ],
   "source": [
    "alpha1, alpha2, alpha3 = sample_three_uniform_numbers()\n",
    "print(f\"alphas: {alpha1}, {alpha2}, {alpha3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DailyEarlyRNN(config.backbonemodel, nclasses=nclasses, input_dim=input_dim, sequencelength=config.sequencelength, hidden_dims=config.hidden_dims).to(config.device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude decision head linear bias from weight decay\n",
    "decay, no_decay = list(), list()\n",
    "for name, param in model.named_parameters():\n",
    "    if name == \"stopping_decision_head.projection.0.bias\":\n",
    "        no_decay.append(param)\n",
    "    else:\n",
    "        decay.append(param)\n",
    "\n",
    "optimizer = torch.optim.AdamW([{'params': no_decay, 'weight_decay': 0, \"lr\": config.learning_rate}, {'params': decay}],\n",
    "                                lr=config.learning_rate, weight_decay=config.weight_decay)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.loss_weight == \"balanced\":\n",
    "    class_weights = train_ds.get_class_weights().to(config.device)\n",
    "else: \n",
    "    class_weights = None\n",
    "\n",
    "if config.loss == \"early_reward\":\n",
    "    criterion = EarlyRewardLoss(alpha=config.alpha, epsilon=config.epsilon, weight=class_weights)\n",
    "elif config.loss == \"stopping_time_proximity\":\n",
    "    criterion = StoppingTimeProximityLoss(alphas=config.alpha, weight=class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross_entropy.shape:  torch.Size([256, 365])\n",
      "classification_loss.shape:  torch.Size([365])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "earliness_reward.shape:  torch.Size([256, 365])\n",
      "earliness_reward.shape:  torch.Size([])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(start_epoch, config\u001b[38;5;241m.\u001b[39mepochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m pbar:\n\u001b[1;32m----> 6\u001b[0m         trainloss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraindataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m         testloss, stats \u001b[38;5;241m=\u001b[39m test_epoch(model, testdataloader, criterion, config\u001b[38;5;241m.\u001b[39mdevice, return_id\u001b[38;5;241m=\u001b[39mtest_ds\u001b[38;5;241m.\u001b[39mreturn_id, daily_timestamps\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdaily_timestamps)\n\u001b[0;32m      9\u001b[0m         \u001b[38;5;66;03m# statistic logging and visualization...\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\anyam\\Desktop\\Master_thesis\\Code\\elects\\coding_test\\..\\utils\\helpers_training.py:70\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[1;34m(model, dataloader, optimizer, criterion, device, extra_padding_list)\u001b[0m\n\u001b[0;32m     67\u001b[0m dict_padding \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextra_padding\u001b[39m\u001b[38;5;124m\"\u001b[39m: extra_padding}\n\u001b[0;32m     68\u001b[0m log_class_probabilities, stopping_criteria \u001b[38;5;241m=\u001b[39m model(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdict_padding)\n\u001b[1;32m---> 70\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_class_probabilities\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m loss\u001b[38;5;241m.\u001b[39misnan()\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m     73\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\anyam\\Desktop\\Master_thesis\\Code\\elects\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\anyam\\Desktop\\Master_thesis\\Code\\elects\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\anyam\\Desktop\\Master_thesis\\Code\\elects\\coding_test\\..\\utils\\losses\\stopping_time_proximity_loss.py:38\u001b[0m, in \u001b[0;36mStoppingTimeProximityLoss.forward\u001b[1;34m(self, log_class_probabilities, timestamps_left, y_true, return_stats)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mearliness_reward.shape: \u001b[39m\u001b[38;5;124m\"\u001b[39m, earliness_reward\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# time proximity reward \u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m proximity_reward \u001b[38;5;241m=\u001b[39m \u001b[43mget_proximity_reward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_class_probabilities\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimestamps_left\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# total loss\u001b[39;00m\n\u001b[0;32m     41\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malphas[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m classification_loss \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malphas[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m earliness_reward \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malphas[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m*\u001b[39m proximity_reward\n",
      "File \u001b[1;32mc:\\Users\\anyam\\Desktop\\Master_thesis\\Code\\elects\\coding_test\\..\\utils\\losses\\stopping_time_proximity_loss.py:68\u001b[0m, in \u001b[0;36mget_proximity_reward\u001b[1;34m(logprobabilities, targets, timestamps_left)\u001b[0m\n\u001b[0;32m     66\u001b[0m class_logprobabilities \u001b[38;5;241m=\u001b[39m logprobabilities[class_mask] \u001b[38;5;66;03m# shape (batchsize, sequencelength)\u001b[39;00m\n\u001b[0;32m     67\u001b[0m indices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(class_logprobabilities\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mto(logprobabilities\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;66;03m# shape (batchsize,)\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m t_finals_class \u001b[38;5;241m=\u001b[39m \u001b[43mt_finals\u001b[49m\u001b[43m[\u001b[49m\u001b[43mclass_mask\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;66;03m# shape (batchsize,)\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# get all pairs of indices of the same class\u001b[39;00m\n\u001b[0;32m     71\u001b[0m pairs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcombinations(indices, with_replacement\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for tensor of dimension 1"
     ]
    }
   ],
   "source": [
    "# ----------------------------- TRAINING -----------------------------\n",
    "start_epoch = 1\n",
    "print(\"starting training...\")\n",
    "with tqdm(range(start_epoch, config.epochs + 1)) as pbar:\n",
    "    for epoch in pbar:\n",
    "        trainloss = train_epoch(model, traindataloader, optimizer, criterion, device=config.device)\n",
    "        testloss, stats = test_epoch(model, testdataloader, criterion, config.device, return_id=test_ds.return_id, daily_timestamps=config.daily_timestamps)\n",
    "\n",
    "        # statistic logging and visualization...\n",
    "        precision, recall, fscore, support = sklearn.metrics.precision_recall_fscore_support(\n",
    "            y_pred=stats[\"predictions_at_t_stop\"][:, 0], y_true=stats[\"targets\"][:, 0], average=\"macro\",\n",
    "            zero_division=0)\n",
    "        accuracy = sklearn.metrics.accuracy_score(\n",
    "            y_pred=stats[\"predictions_at_t_stop\"][:, 0], y_true=stats[\"targets\"][:, 0])\n",
    "        kappa = sklearn.metrics.cohen_kappa_score(\n",
    "            stats[\"predictions_at_t_stop\"][:, 0], stats[\"targets\"][:, 0])\n",
    "\n",
    "        classification_loss = stats[\"classification_loss\"].mean()\n",
    "        earliness_reward = stats[\"earliness_reward\"].mean()\n",
    "        earliness = 1 - (stats[\"t_stop\"].mean() / (config.sequencelength - 1))\n",
    "        harmonic_mean = harmonic_mean_score(accuracy, stats[\"classification_earliness\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.0982, -2.2887, -2.2046,  ..., -2.1571, -2.2635, -2.3104],\n",
       "         [-2.0976, -2.2901, -2.2015,  ..., -2.1580, -2.2649, -2.3124],\n",
       "         [-2.0978, -2.2876, -2.1999,  ..., -2.1596, -2.2658, -2.3163],\n",
       "         ...,\n",
       "         [-2.0849, -2.2865, -2.1784,  ..., -2.1551, -2.2731, -2.3009],\n",
       "         [-2.0886, -2.2877, -2.1736,  ..., -2.1570, -2.2730, -2.3015],\n",
       "         [-2.0836, -2.2922, -2.1846,  ..., -2.1593, -2.2680, -2.3033]],\n",
       "\n",
       "        [[-2.0980, -2.2894, -2.2048,  ..., -2.1548, -2.2627, -2.3100],\n",
       "         [-2.0965, -2.2894, -2.2042,  ..., -2.1555, -2.2657, -2.3114],\n",
       "         [-2.0957, -2.2876, -2.1982,  ..., -2.1533, -2.2757, -2.3100],\n",
       "         ...,\n",
       "         [-2.0932, -2.2766, -2.1814,  ..., -2.1685, -2.2705, -2.3067],\n",
       "         [-2.0946, -2.2819, -2.1834,  ..., -2.1703, -2.2645, -2.3107],\n",
       "         [-2.0944, -2.2828, -2.1855,  ..., -2.1670, -2.2623, -2.3126]],\n",
       "\n",
       "        [[-2.0982, -2.2886, -2.2041,  ..., -2.1561, -2.2637, -2.3101],\n",
       "         [-2.0961, -2.2885, -2.2031,  ..., -2.1581, -2.2656, -2.3101],\n",
       "         [-2.0989, -2.2873, -2.1979,  ..., -2.1592, -2.2747, -2.3091],\n",
       "         ...,\n",
       "         [-2.0993, -2.2858, -2.1805,  ..., -2.1582, -2.2741, -2.3076],\n",
       "         [-2.1001, -2.2823, -2.1807,  ..., -2.1624, -2.2679, -2.3091],\n",
       "         [-2.1014, -2.2849, -2.1875,  ..., -2.1590, -2.2651, -2.3115]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.0984, -2.2885, -2.2045,  ..., -2.1560, -2.2623, -2.3120],\n",
       "         [-2.0978, -2.2912, -2.2016,  ..., -2.1568, -2.2638, -2.3128],\n",
       "         [-2.0952, -2.2939, -2.1922,  ..., -2.1625, -2.2669, -2.3098],\n",
       "         ...,\n",
       "         [-2.0927, -2.2867, -2.1786,  ..., -2.1560, -2.2744, -2.3096],\n",
       "         [-2.0935, -2.2867, -2.1754,  ..., -2.1616, -2.2710, -2.3102],\n",
       "         [-2.0932, -2.2879, -2.1803,  ..., -2.1629, -2.2660, -2.3095]],\n",
       "\n",
       "        [[-2.0982, -2.2900, -2.2044,  ..., -2.1562, -2.2632, -2.3108],\n",
       "         [-2.0957, -2.2894, -2.2026,  ..., -2.1570, -2.2634, -2.3128],\n",
       "         [-2.1001, -2.2861, -2.1923,  ..., -2.1518, -2.2670, -2.3144],\n",
       "         ...,\n",
       "         [-2.0978, -2.2948, -2.1743,  ..., -2.1648, -2.2678, -2.3014],\n",
       "         [-2.0967, -2.2887, -2.1781,  ..., -2.1702, -2.2624, -2.3034],\n",
       "         [-2.0917, -2.2894, -2.1820,  ..., -2.1699, -2.2625, -2.3056]],\n",
       "\n",
       "        [[-2.0983, -2.2906, -2.2043,  ..., -2.1549, -2.2628, -2.3114],\n",
       "         [-2.0963, -2.2906, -2.2050,  ..., -2.1580, -2.2638, -2.3106],\n",
       "         [-2.1007, -2.2804, -2.1987,  ..., -2.1570, -2.2735, -2.3035],\n",
       "         ...,\n",
       "         [-2.0950, -2.2880, -2.1769,  ..., -2.1635, -2.2578, -2.3054],\n",
       "         [-2.0903, -2.2868, -2.1770,  ..., -2.1627, -2.2631, -2.3082],\n",
       "         [-2.0922, -2.2879, -2.1848,  ..., -2.1572, -2.2615, -2.3132]]],\n",
       "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_class_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[364., 364., 364.,  ..., 364., 364., 364.],\n",
       "        [364., 364., 364.,  ..., 364., 364., 364.],\n",
       "        [364., 364., 364.,  ..., 364., 364., 364.],\n",
       "        ...,\n",
       "        [364., 364., 364.,  ..., 364., 364., 364.],\n",
       "        [364., 364., 364.,  ..., 364., 364., 364.],\n",
       "        [364., 364., 364.,  ..., 364., 364., 364.]], device='cuda:0',\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamps_left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes\n",
      "logprobabilities torch.Size([256, 365, 9])\n",
      "timestamps_left torch.Size([256, 365])\n",
      "predictions_at_t_stop torch.Size([256])\n",
      "t_stop torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "logprobabilities, timestamps_left, predictions_at_t_stop, t_stop = model.predict(X.to(config.device))\n",
    "print(\"shapes\")\n",
    "print(\"logprobabilities\", logprobabilities.shape)\n",
    "print(\"timestamps_left\", timestamps_left.shape)\n",
    "print(\"predictions_at_t_stop\", predictions_at_t_stop.shape)\n",
    "print(\"t_stop\", t_stop.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobabilities tensor([[[-2.0979, -2.2886, -2.2047,  ..., -2.1557, -2.2622, -2.3116],\n",
      "         [-2.0968, -2.2899, -2.2028,  ..., -2.1575, -2.2649, -2.3119],\n",
      "         [-2.0901, -2.2942, -2.1983,  ..., -2.1591, -2.2760, -2.3093],\n",
      "         ...,\n",
      "         [-2.0942, -2.2873, -2.1760,  ..., -2.1637, -2.2672, -2.3101],\n",
      "         [-2.0943, -2.2934, -2.1836,  ..., -2.1627, -2.2637, -2.3133],\n",
      "         [-2.0884, -2.2939, -2.1864,  ..., -2.1599, -2.2589, -2.3139]],\n",
      "\n",
      "        [[-2.0975, -2.2887, -2.2056,  ..., -2.1547, -2.2636, -2.3114],\n",
      "         [-2.0956, -2.2872, -2.2062,  ..., -2.1556, -2.2662, -2.3116],\n",
      "         [-2.0879, -2.2856, -2.2042,  ..., -2.1556, -2.2781, -2.3077],\n",
      "         ...,\n",
      "         [-2.0989, -2.2763, -2.1828,  ..., -2.1632, -2.2744, -2.3030],\n",
      "         [-2.0996, -2.2766, -2.1820,  ..., -2.1661, -2.2648, -2.3058],\n",
      "         [-2.0968, -2.2773, -2.1851,  ..., -2.1677, -2.2617, -2.3111]],\n",
      "\n",
      "        [[-2.0971, -2.2883, -2.2053,  ..., -2.1545, -2.2617, -2.3121],\n",
      "         [-2.0945, -2.2890, -2.2043,  ..., -2.1569, -2.2651, -2.3140],\n",
      "         [-2.0958, -2.2867, -2.1955,  ..., -2.1549, -2.2759, -2.3097],\n",
      "         ...,\n",
      "         [-2.1008, -2.2820, -2.1883,  ..., -2.1499, -2.2549, -2.3030],\n",
      "         [-2.1041, -2.2812, -2.1863,  ..., -2.1547, -2.2542, -2.3095],\n",
      "         [-2.0962, -2.2853, -2.1883,  ..., -2.1580, -2.2590, -2.3133]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.0978, -2.2885, -2.2045,  ..., -2.1561, -2.2638, -2.3104],\n",
      "         [-2.0959, -2.2909, -2.2034,  ..., -2.1571, -2.2644, -2.3108],\n",
      "         [-2.0878, -2.2899, -2.1968,  ..., -2.1641, -2.2697, -2.3065],\n",
      "         ...,\n",
      "         [-2.0817, -2.2870, -2.1719,  ..., -2.1608, -2.2728, -2.3105],\n",
      "         [-2.0882, -2.2851, -2.1808,  ..., -2.1621, -2.2634, -2.3114],\n",
      "         [-2.0931, -2.2835, -2.1845,  ..., -2.1603, -2.2607, -2.3142]],\n",
      "\n",
      "        [[-2.0992, -2.2877, -2.2056,  ..., -2.1557, -2.2627, -2.3111],\n",
      "         [-2.0993, -2.2890, -2.2014,  ..., -2.1573, -2.2644, -2.3110],\n",
      "         [-2.1000, -2.2899, -2.1917,  ..., -2.1548, -2.2721, -2.3072],\n",
      "         ...,\n",
      "         [-2.0936, -2.2862, -2.1748,  ..., -2.1715, -2.2665, -2.2994],\n",
      "         [-2.0936, -2.2879, -2.1759,  ..., -2.1669, -2.2625, -2.3031],\n",
      "         [-2.0923, -2.2922, -2.1837,  ..., -2.1616, -2.2629, -2.3103]],\n",
      "\n",
      "        [[-2.0979, -2.2885, -2.2051,  ..., -2.1552, -2.2637, -2.3114],\n",
      "         [-2.0965, -2.2908, -2.2026,  ..., -2.1570, -2.2646, -2.3123],\n",
      "         [-2.0982, -2.2875, -2.1943,  ..., -2.1563, -2.2736, -2.3041],\n",
      "         ...,\n",
      "         [-2.0934, -2.2852, -2.1723,  ..., -2.1609, -2.2726, -2.3090],\n",
      "         [-2.0856, -2.2845, -2.1740,  ..., -2.1620, -2.2700, -2.3113],\n",
      "         [-2.0906, -2.2833, -2.1781,  ..., -2.1610, -2.2683, -2.3131]]],\n",
      "       device='cuda:0')\n",
      "timestamps_left tensor([[364., 364., 364.,  ..., 364., 364., 364.],\n",
      "        [364., 364., 364.,  ..., 364., 364., 364.],\n",
      "        [364., 364., 364.,  ..., 364., 364., 364.],\n",
      "        ...,\n",
      "        [364., 364., 364.,  ..., 364., 364., 364.],\n",
      "        [364., 364., 364.,  ..., 364., 364., 364.],\n",
      "        [364., 364., 364.,  ..., 364., 364., 364.]], device='cuda:0')\n",
      "predictions_at_t_stop tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "t_stop tensor([364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364,\n",
      "        364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364,\n",
      "        364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364,\n",
      "        364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364,\n",
      "        364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364,\n",
      "        364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364,\n",
      "        364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364,\n",
      "        364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364,\n",
      "        364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364,\n",
      "        364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364,\n",
      "        364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364,\n",
      "        364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364,\n",
      "        364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364,\n",
      "        364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364,\n",
      "        364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364,\n",
      "        364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364,\n",
      "        364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364,\n",
      "        364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364, 364,\n",
      "        364, 364, 364, 364])\n"
     ]
    }
   ],
   "source": [
    "print(\"logprobabilities\", logprobabilities)\n",
    "print(\"timestamps_left\", timestamps_left)\n",
    "print(\"predictions_at_t_stop\", predictions_at_t_stop)\n",
    "print(\"t_stop\", t_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
