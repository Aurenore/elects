{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Notebook - for developing code \n",
    "## test epoch with extra padding \n",
    "test new functions with extra padding. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import os \n",
    "os.environ['MPLCONFIGDIR'] = '/myhome'\n",
    "# sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), os.path.pardir)))\n",
    "from data import BavarianCrops, BreizhCrops, SustainbenchCrops, ModisCDL\n",
    "from torch.utils.data import DataLoader\n",
    "from earlyrnn import EarlyRNN\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from utils.losses.early_reward_loss import EarlyRewardLoss\n",
    "import sklearn.metrics\n",
    "import pandas as pd\n",
    "import wandb\n",
    "from utils.plots import plot_label_distribution_datasets, boxplot_stopping_times\n",
    "from utils.doy import get_doys_dict_test, get_doy_stop, create_sorted_doys_dict_test, get_approximated_doys_dict\n",
    "from utils.helpers_training import parse_args, train_epoch, test_epoch\n",
    "from utils.metrics import harmonic_mean_score\n",
    "import matplotlib.pyplot as plt\n",
    "from models.model_helpers import count_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "def parse_args(args=None):\n",
    "    parser = argparse.ArgumentParser(description='Run ELECTS Early Classification training on the BavarianCrops dataset.')\n",
    "    parser.add_argument('--backbonemodel', type=str, default=\"LSTM\", choices=[\"LSTM\", \"TempCNN\", \"Transformer\"], help=\"backbone model\")\n",
    "    parser.add_argument('--dataset', type=str, default=\"bavariancrops\", choices=[\"bavariancrops\",\"breizhcrops\", \"ghana\", \"southsudan\",\"unitedstates\"], help=\"dataset\")\n",
    "    parser.add_argument('--alpha', type=float, default=0.5, help=\"trade-off parameter of earliness and accuracy (eq 6): \"\n",
    "                                                                 \"1=full weight on accuracy; 0=full weight on earliness\")\n",
    "    parser.add_argument('--epsilon', type=float, default=10, help=\"additive smoothing parameter that helps the \"\n",
    "                                                                  \"model recover from too early classifications (eq 7)\")\n",
    "    parser.add_argument('--learning-rate', type=float, default=1e-3, help=\"Optimizer learning rate\")\n",
    "    parser.add_argument('--weight-decay', type=float, default=0, help=\"weight_decay\")\n",
    "    parser.add_argument('--patience', type=int, default=30, help=\"Early stopping patience\")\n",
    "    parser.add_argument('--device', type=str, default=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "                        choices=[\"cuda\", \"cpu\"], help=\"'cuda' (GPU) or 'cpu' device to run the code. \"\n",
    "                                                     \"defaults to 'cuda' if GPU is available, otherwise 'cpu'\")\n",
    "    parser.add_argument('--epochs', type=int, default=100, help=\"number of training epochs\")\n",
    "    parser.add_argument('--sequencelength', type=int, default=70, help=\"sequencelength of the time series. If samples are shorter, \"\n",
    "                                                                \"they are zero-padded until this length; \"\n",
    "                                                                \"if samples are longer, they will be undersampled\")\n",
    "    parser.add_argument('--hidden-dims', type=int, default=64, help=\"number of hidden dimensions in the backbone model\")\n",
    "    parser.add_argument('--batchsize', type=int, default=256, help=\"number of samples per batch\")\n",
    "    parser.add_argument('--dataroot', type=str, default=os.path.join(os.environ.get(\"HOME\", os.environ.get(\"USERPROFILE\")),\"elects_data\"), help=\"directory to download the \"\n",
    "                                                                                 \"BavarianCrops dataset (400MB).\"\n",
    "                                                                                 \"Defaults to home directory.\")\n",
    "    parser.add_argument('--snapshot', type=str, default=\"snapshots/model.pth\",\n",
    "                        help=\"pytorch state dict snapshot file\")\n",
    "    parser.add_argument('--resume', action='store_true')\n",
    "\n",
    "    if args is not None:\n",
    "        args = parser.parse_args(args)\n",
    "    else:\n",
    "        args = parser.parse_args()\n",
    "\n",
    "    if args.patience < 0:\n",
    "        args.patience = None\n",
    "\n",
    "    return args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is available:  cuda\n",
      "Namespace(backbonemodel='TempCNN', dataset='breizhcrops', alpha=0.5, epsilon=10, learning_rate=0.001, weight_decay=0, patience=30, device='cuda', epochs=10, sequencelength=70, hidden_dims=16, batchsize=256, dataroot='C:\\\\Users\\\\anyam\\\\elects_data', snapshot='snapshots/model.pth', resume=False)\n"
     ]
    }
   ],
   "source": [
    "# Example of how to call parse_args with custom arguments in a notebook\n",
    "custom_args = \"--backbonemodel TempCNN --dataset breizhcrops --epochs 10 --hidden-dims 16\".split()\n",
    "args = parse_args(custom_args)\n",
    "print(\"cuda is available: \", args.device)\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "wandb: Currently logged in as: aurenore. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\anyam\\Desktop\\Master_thesis\\Code\\elects\\EDA\\wandb\\run-20240404_165004-ljad4fw6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aurenore/ELECTS/runs/ljad4fw6/workspace' target=\"_blank\">genial-brook-86</a></strong> to <a href='https://wandb.ai/aurenore/ELECTS' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aurenore/ELECTS' target=\"_blank\">https://wandb.ai/aurenore/ELECTS</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aurenore/ELECTS/runs/ljad4fw6/workspace' target=\"_blank\">https://wandb.ai/aurenore/ELECTS/runs/ljad4fw6/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/aurenore/ELECTS/runs/ljad4fw6?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x255666d4090>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir = \"/mydata/studentanya/anya/wandb/\"\n",
    "wandb.init(\n",
    "        dir=None,\n",
    "        project=\"ELECTS\",\n",
    "        notes=\"first experimentations with ELECTS\",\n",
    "        tags=[\"ELECTS\", args.dataset, \"with_doys_boxplot\", args.backbonemodel],\n",
    "        config={\n",
    "        \"backbonemodel\": args.backbonemodel,\n",
    "        \"dataset\": args.dataset,\n",
    "        \"alpha\": args.alpha,\n",
    "        \"epsilon\": args.epsilon,\n",
    "        \"learning_rate\": args.learning_rate,\n",
    "        \"weight_decay\": args.weight_decay,\n",
    "        \"patience\": args.patience,\n",
    "        \"device\": args.device,\n",
    "        \"epochs\": args.epochs,\n",
    "        \"sequencelength\": args.sequencelength,\n",
    "        \"hidden_dims\": args.hidden_dims,\n",
    "        \"batchsize\": args.batchsize,\n",
    "        \"dataroot\": args.dataroot,\n",
    "        \"snapshot\": args.snapshot,\n",
    "        \"resume\": args.resume,\n",
    "        \"architecture\": \"EarlyRNN\",\n",
    "        \"optimizer\": \"AdamW\",\n",
    "        \"criterion\": \"EarlyRewardLoss\",\n",
    "        }\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get doys dict test\n",
      "get doys dict test done\n",
      "get train and validation data...\n",
      "2559635960 2559635960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading data into RAM: 100%|██████████| 178613/178613 [01:18<00:00, 2287.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2253658856 2253658856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading data into RAM: 100%|██████████| 140645/140645 [01:21<00:00, 1727.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2493572704 2493572704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading data into RAM: 100%|██████████| 166391/166391 [01:50<00:00, 1501.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class names: ['barley' 'wheat' 'rapeseed' 'corn' 'sunflower' 'orchards' 'nuts'\n",
      " 'permanent meadows' 'temporary meadows']\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------- LOAD DATASET -----------------------------\n",
    "\n",
    "if args.dataset == \"bavariancrops\":\n",
    "    dataroot = os.path.join(args.dataroot,\"bavariancrops\")\n",
    "    nclasses = 7\n",
    "    input_dim = 13\n",
    "    class_weights = None\n",
    "    train_ds = BavarianCrops(root=dataroot,partition=\"train\", sequencelength=args.sequencelength)\n",
    "    test_ds = BavarianCrops(root=dataroot,partition=\"valid\", sequencelength=args.sequencelength)\n",
    "    class_names = test_ds.classes\n",
    "elif args.dataset == \"unitedstates\":\n",
    "    args.dataroot = \"/data/modiscdl/\"\n",
    "    args.sequencelength = 24\n",
    "    dataroot = args.dataroot\n",
    "    nclasses = 8\n",
    "    input_dim = 1\n",
    "    train_ds = ModisCDL(root=dataroot,partition=\"train\", sequencelength=args.sequencelength)\n",
    "    test_ds = ModisCDL(root=dataroot,partition=\"valid\", sequencelength=args.sequencelength)\n",
    "elif args.dataset == \"breizhcrops\":\n",
    "    dataroot = os.path.join(args.dataroot,\"breizhcrops\")\n",
    "    nclasses = 9\n",
    "    input_dim = 13\n",
    "    print(\"get doys dict test\")\n",
    "    doys_dict_test = get_doys_dict_test(dataroot=os.path.join(args.dataroot,args.dataset))\n",
    "    length_sorted_doy_dict_test = create_sorted_doys_dict_test(doys_dict_test)\n",
    "    print(\"get doys dict test done\")\n",
    "    print(\"get train and validation data...\")\n",
    "    train_ds = BreizhCrops(root=dataroot,partition=\"train\", sequencelength=args.sequencelength)\n",
    "    test_ds = BreizhCrops(root=dataroot,partition=\"valid\", sequencelength=args.sequencelength)\n",
    "    class_names = test_ds.ds.classname\n",
    "    print(\"class names:\", class_names)\n",
    "elif args.dataset in [\"ghana\"]:\n",
    "    use_s2_only = False\n",
    "    average_pixel = False\n",
    "    max_n_pixels = 50\n",
    "    dataroot = args.dataroot\n",
    "    nclasses = 4\n",
    "    input_dim = 12 if use_s2_only else 19  # 12 sentinel 2 + 3 x sentinel 1 + 4 * planet\n",
    "    args.epochs = 500\n",
    "    args.sequencelength = 365\n",
    "    train_ds = SustainbenchCrops(root=dataroot,partition=\"train\", sequencelength=args.sequencelength,\n",
    "                                    country=\"ghana\",\n",
    "                                    use_s2_only=use_s2_only, average_pixel=average_pixel,\n",
    "                                    max_n_pixels=max_n_pixels)\n",
    "    val_ds = SustainbenchCrops(root=dataroot,partition=\"val\", sequencelength=args.sequencelength,\n",
    "                                country=\"ghana\", use_s2_only=use_s2_only, average_pixel=average_pixel,\n",
    "                                max_n_pixels=max_n_pixels)\n",
    "\n",
    "    train_ds = torch.utils.data.ConcatDataset([train_ds, val_ds])\n",
    "\n",
    "    test_ds = SustainbenchCrops(root=dataroot,partition=\"test\", sequencelength=args.sequencelength,\n",
    "                                country=\"ghana\", use_s2_only=use_s2_only, average_pixel=average_pixel,\n",
    "                                max_n_pixels=max_n_pixels)\n",
    "    class_names = test_ds.classes\n",
    "elif args.dataset in [\"southsudan\"]:\n",
    "    use_s2_only = False\n",
    "    dataroot = args.dataroot\n",
    "    nclasses = 4\n",
    "    args.sequencelength = 365\n",
    "    input_dim = 12 if use_s2_only else 19 # 12 sentinel 2 + 3 x sentinel 1 + 4 * planet\n",
    "    args.epochs = 500\n",
    "    train_ds = SustainbenchCrops(root=dataroot,partition=\"train\", sequencelength=args.sequencelength, country=\"southsudan\", use_s2_only=use_s2_only)\n",
    "    val_ds = SustainbenchCrops(root=dataroot,partition=\"val\", sequencelength=args.sequencelength, country=\"southsudan\", use_s2_only=use_s2_only)\n",
    "\n",
    "    train_ds = torch.utils.data.ConcatDataset([train_ds, val_ds])\n",
    "    test_ds = SustainbenchCrops(root=dataroot, partition=\"val\", sequencelength=args.sequencelength,\n",
    "                                country=\"southsudan\", use_s2_only=use_s2_only)\n",
    "    class_names = test_ds.classes\n",
    "\n",
    "else:\n",
    "    raise ValueError(f\"dataset {args.dataset} not recognized\")\n",
    "\n",
    "traindataloader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=args.batchsize)\n",
    "testdataloader = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=args.batchsize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------- VISUALIZATION: label distribution -----------------------------\n",
    "# datasets = [train_ds, test_ds]\n",
    "# sets_labels = [\"Train\", \"Validation\"]\n",
    "# fig, ax = plt.subplots(figsize=(15, 7))\n",
    "# fig, ax = plot_label_distribution_datasets(datasets, sets_labels, fig, ax, title='Label distribution', labels_names=class_names)\n",
    "# wandb.log({\"label_distribution\": wandb.Image(fig)})\n",
    "# plt.close(fig)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence_lengths_train [25, 50]\n",
      "extra_padding_list [45, 20]\n"
     ]
    }
   ],
   "source": [
    "step_timestamp_padding = 25\n",
    "sequence_lengths_train = [step_timestamp_padding*i for i in range(1, args.sequencelength//step_timestamp_padding+1)]\n",
    "print(\"sequence_lengths_train\", sequence_lengths_train)\n",
    "extra_padding_list = [args.sequencelength - i for i in sequence_lengths_train]\n",
    "print(\"extra_padding_list\", extra_padding_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 8,196 trainable parameters.\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------- SET UP MODEL -----------------------------\n",
    "#model = EarlyRNN(nclasses=nclasses, input_dim=input_dim, hidden_dims=64, sequencelength=args.sequencelength).to(args.device)\n",
    "# nclasses=9\n",
    "# input_dim=13\n",
    "model = EarlyRNN(args.backbonemodel, nclasses=nclasses, input_dim=input_dim, sequencelength=args.sequencelength, kernel_size=7, hidden_dims=args.hidden_dims).to(args.device)\n",
    "print(f\"The model has {count_parameters(model):,} trainable parameters.\")\n",
    "\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=args.learning_rate, weight_decay=args.weight_decay)\n",
    "\n",
    "# exclude decision head linear bias from weight decay\n",
    "decay, no_decay = list(), list()\n",
    "for name, param in model.named_parameters():\n",
    "    if name == \"stopping_decision_head.projection.0.bias\":\n",
    "        no_decay.append(param)\n",
    "    else:\n",
    "        decay.append(param)\n",
    "\n",
    "optimizer = torch.optim.AdamW([{'params': no_decay, 'weight_decay': 0, \"lr\": args.learning_rate}, {'params': decay}],\n",
    "                                lr=args.learning_rate, weight_decay=args.weight_decay)\n",
    "\n",
    "criterion = EarlyRewardLoss(alpha=args.alpha, epsilon=args.epsilon)\n",
    "\n",
    "if args.resume and os.path.exists(args.snapshot):\n",
    "    model.load_state_dict(torch.load(args.snapshot, map_location=args.device))\n",
    "    optimizer_snapshot = os.path.join(os.path.dirname(args.snapshot),\n",
    "                                        os.path.basename(args.snapshot).replace(\".pth\", \"_optimizer.pth\")\n",
    "                                        )\n",
    "    optimizer.load_state_dict(torch.load(optimizer_snapshot, map_location=args.device))\n",
    "    df = pd.read_csv(args.snapshot + \".csv\")\n",
    "    train_stats = df.to_dict(\"records\")\n",
    "    start_epoch = train_stats[-1][\"epoch\"]\n",
    "    print(f\"resuming from {args.snapshot} epoch {start_epoch}\")\n",
    "else:\n",
    "    train_stats = []\n",
    "    start_epoch = 1\n",
    "\n",
    "not_improved = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloss = train_epoch(model, traindataloader, optimizer, criterion, device=args.device, extra_padding_list=extra_padding_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "def test_epoch(model, dataloader, criterion, device, extra_padding_list:list=[0]):\n",
    "    model.eval()\n",
    "\n",
    "    stats = []\n",
    "    losses = []\n",
    "    slengths = []\n",
    "\n",
    "    # sort the padding in descending order\n",
    "    extra_padding_list = sorted(extra_padding_list, reverse=True)\n",
    "\n",
    "    for ids, batch in enumerate(dataloader):\n",
    "        X, y_true = batch\n",
    "        X, y_true = X.to(device), y_true.to(device)\n",
    "\n",
    "        seqlengths = (X[:,:,0] != 0).sum(1)\n",
    "        slengths.append(seqlengths.cpu().detach())\n",
    "        \n",
    "        # by default, we predict the sequence with the smallest padding\n",
    "        extra_padding = extra_padding_list[-1]\n",
    "        dict_padding = {\"extra_padding\": extra_padding}\n",
    "\n",
    "        # predict the sequence with the smallest padding\n",
    "        log_class_probabilities, probability_stopping, predictions_at_t_stop, t_stop = model.predict(X, **dict_padding)\n",
    "            \n",
    "        if len(extra_padding_list) > 1:\n",
    "            # mask for sequences that are not predicted yet\n",
    "            unpredicted_seq_mask = torch.ones(X.shape[0], dtype=bool).to(device)\n",
    "            # index for the extra_padding_list\n",
    "            i=0 \n",
    "            while unpredicted_seq_mask.any() and i < len(extra_padding_list)-1:\n",
    "                extra_padding = extra_padding_list[i]\n",
    "                dict_padding = {\"extra_padding\": extra_padding}\n",
    "                log_class_probabilities_temp, probability_stopping_temp, predictions_at_t_stop_temp, t_stop_temp = model.predict(X, **dict_padding)\n",
    "                \n",
    "                # update the mask if t_stop is different from the length of the sequence (i.e. the sequence is predicted before its end)\n",
    "                unpredicted_seq_mask = unpredicted_seq_mask*(t_stop >= seqlengths-extra_padding)\n",
    "            \n",
    "                # update the metrics data with the mask of predicted sequences\n",
    "                log_class_probabilities = torch.where(~unpredicted_seq_mask.unsqueeze(1).unsqueeze(-1), log_class_probabilities_temp, log_class_probabilities)\n",
    "                probability_stopping = torch.where(~unpredicted_seq_mask.unsqueeze(1), probability_stopping_temp, probability_stopping)\n",
    "                predictions_at_t_stop = torch.where(~unpredicted_seq_mask, predictions_at_t_stop_temp, predictions_at_t_stop)\n",
    "                t_stop = torch.where(~unpredicted_seq_mask, t_stop_temp, t_stop)\n",
    "                i+=1\n",
    "\n",
    "        loss, stat = criterion(log_class_probabilities, probability_stopping, y_true, return_stats=True)\n",
    "        stat[\"loss\"] = loss.cpu().detach().numpy()\n",
    "        stat[\"probability_stopping\"] = probability_stopping.cpu().detach().numpy()\n",
    "        stat[\"class_probabilities\"] = log_class_probabilities.exp().cpu().detach().numpy()\n",
    "        stat[\"predictions_at_t_stop\"] = predictions_at_t_stop.unsqueeze(-1).cpu().detach().numpy()\n",
    "        stat[\"t_stop\"] = t_stop.unsqueeze(-1).cpu().detach().numpy()\n",
    "        stat[\"targets\"] = y_true.cpu().detach().numpy()\n",
    "        stat[\"ids\"] = ids\n",
    "\n",
    "        stats.append(stat)\n",
    "        losses.append(loss.cpu().detach().numpy())\n",
    "\n",
    "    # list of dicts to dict of lists\n",
    "    stats = {k: np.vstack([dic[k] for dic in stats]) for k in stats[0]}\n",
    "    stats[\"seqlengths\"] = torch.cat(slengths).numpy()\n",
    "    stats[\"classification_earliness\"] = np.mean(stats[\"t_stop\"].flatten()/stats[\"seqlengths\"])\n",
    "\n",
    "    return np.stack(losses).mean(), stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "testloss, stats = test_epoch(model, testdataloader, criterion, args.device, extra_padding_list=extra_padding_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch_old(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "\n",
    "    stats = []\n",
    "    losses = []\n",
    "    slengths = []\n",
    "    for ids, batch in enumerate(dataloader):\n",
    "        X, y_true = batch\n",
    "        X, y_true = X.to(device), y_true.to(device)\n",
    "\n",
    "        seqlengths = (X[:,:,0] != 0).sum(1)\n",
    "        slengths.append(seqlengths.cpu().detach())\n",
    "\n",
    "        log_class_probabilities, probability_stopping, predictions_at_t_stop, t_stop = model.predict(X)\n",
    "        loss, stat = criterion(log_class_probabilities, probability_stopping, y_true, return_stats=True)\n",
    "\n",
    "        stat[\"loss\"] = loss.cpu().detach().numpy()\n",
    "        stat[\"probability_stopping\"] = probability_stopping.cpu().detach().numpy()\n",
    "        stat[\"class_probabilities\"] = log_class_probabilities.exp().cpu().detach().numpy()\n",
    "        stat[\"predictions_at_t_stop\"] = predictions_at_t_stop.unsqueeze(-1).cpu().detach().numpy()\n",
    "        stat[\"t_stop\"] = t_stop.unsqueeze(-1).cpu().detach().numpy()\n",
    "        stat[\"targets\"] = y_true.cpu().detach().numpy()\n",
    "        stat[\"ids\"] = ids\n",
    "\n",
    "        stats.append(stat)\n",
    "\n",
    "        losses.append(loss.cpu().detach().numpy())\n",
    "\n",
    "    # list of dicts to dict of lists\n",
    "    stats = {k: np.vstack([dic[k] for dic in stats]) for k in stats[0]}\n",
    "    stats[\"seqlengths\"] = torch.cat(slengths).numpy()\n",
    "    stats[\"classification_earliness\"] = np.mean(stats[\"t_stop\"].flatten()/stats[\"seqlengths\"])\n",
    "\n",
    "    return np.stack(losses).mean(), stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time test_epoch 106.10727453231812\n",
      "time test_epoch_old 83.68865251541138\n",
      "time test_epoch_old2 92.16113233566284\n"
     ]
    }
   ],
   "source": [
    "# measure the time of the test_epoch function\n",
    "seed = 0\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "testloss, stats = test_epoch(model, testdataloader, criterion, args.device, extra_padding_list=[0])\n",
    "end = time.time()\n",
    "print(\"time test_epoch\", end-start)\n",
    "start = time.time()\n",
    "testloss_old, stats_old = test_epoch_old(model, testdataloader, criterion, args.device)\n",
    "end = time.time()\n",
    "print(\"time test_epoch_old\", end-start)\n",
    "start = time.time()\n",
    "testloss2, stats_old2 = test_epoch_old(model, testdataloader, criterion, args.device)\n",
    "end = time.time()\n",
    "print(\"time test_epoch_old2\", end-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testloss 4.4697895\n",
      "testloss_old 4.4675364\n",
      "testloss2 4.4680147\n",
      "difference: 0.0022530556\n",
      "difference2: 0.00047826767\n"
     ]
    }
   ],
   "source": [
    "#both should give the same result: \n",
    "print(\"testloss\", testloss)\n",
    "print(\"testloss_old\", testloss_old)\n",
    "print(\"testloss2\", testloss2)\n",
    "print(\"difference:\", np.abs(testloss-testloss_old))\n",
    "print(\"difference2:\", np.abs(testloss_old-testloss2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allclose: True\n",
      "allclose2: True\n"
     ]
    }
   ],
   "source": [
    "key = \"targets\"\n",
    "# check that the results are the same for key \n",
    "print(\"allclose:\", np.allclose(stats[key], stats_old[key]))\n",
    "print(\"allclose2:\", np.allclose(stats[key], stats_old2[key]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ----------------------------- TRAINING -----------------------------\n",
    "# print(\"starting training...\")\n",
    "# with tqdm(range(start_epoch, args.epochs + 1)) as pbar:\n",
    "#     for epoch in pbar:\n",
    "#         trainloss = train_epoch(model, traindataloader, optimizer, criterion, device=args.device, extra_padding_list=extra_padding_list)\n",
    "#         print(\"finished training for epoch \", epoch)\n",
    "#         testloss, stats = test_epoch(model, testdataloader, criterion, args.device, thresh_stop=0.8, extra_padding_list=extra_padding_list)\n",
    "\n",
    "#         # statistic logging and visualization...\n",
    "#         precision, recall, fscore, support = sklearn.metrics.precision_recall_fscore_support(\n",
    "#             y_pred=stats[\"predictions_at_t_stop\"][:, 0], y_true=stats[\"targets\"][:, 0], average=\"macro\",\n",
    "#             zero_division=0)\n",
    "#         accuracy = sklearn.metrics.accuracy_score(\n",
    "#             y_pred=stats[\"predictions_at_t_stop\"][:, 0], y_true=stats[\"targets\"][:, 0])\n",
    "#         kappa = sklearn.metrics.cohen_kappa_score(\n",
    "#             stats[\"predictions_at_t_stop\"][:, 0], stats[\"targets\"][:, 0])\n",
    "\n",
    "#         classification_loss = stats[\"classification_loss\"].mean()\n",
    "#         earliness_reward = stats[\"earliness_reward\"].mean()\n",
    "#         earliness = 1 - (stats[\"t_stop\"].mean() / (args.sequencelength - 1))\n",
    "#         harmonic_mean = harmonic_mean_score(accuracy, stats[\"classification_earliness\"])\n",
    "\n",
    "#         # ----------------------------- LOGGING -----------------------------\n",
    "#         train_stats.append(\n",
    "#             dict(\n",
    "#                 epoch=epoch,\n",
    "#                 trainloss=trainloss,\n",
    "#                 testloss=testloss,\n",
    "#                 accuracy=accuracy,\n",
    "#                 precision=precision,\n",
    "#                 recall=recall,\n",
    "#                 fscore=fscore,\n",
    "#                 kappa=kappa,\n",
    "#                 elects_earliness=earliness,\n",
    "#                 classification_loss=classification_loss,\n",
    "#                 earliness_reward=earliness_reward,\n",
    "#                 classification_earliness=stats[\"classification_earliness\"],\n",
    "#                 harmonic_mean=harmonic_mean,\n",
    "#             )\n",
    "#         )\n",
    "#         fig_boxplot, ax_boxplot = plt.subplots(figsize=(15, 7))\n",
    "#         doys_dict = get_approximated_doys_dict(stats[\"seqlengths\"], length_sorted_doy_dict_test)\n",
    "#         doys_stop = get_doy_stop(stats, doys_dict)\n",
    "#         fig_boxplot, _ = boxplot_stopping_times(doys_stop, stats, fig_boxplot, ax_boxplot, class_names)\n",
    "#         wandb.log({\n",
    "#                 \"loss\": {\"trainloss\": trainloss, \"testloss\": testloss},\n",
    "#                 \"accuracy\": accuracy,\n",
    "#                 \"precision\": precision,\n",
    "#                 \"recall\": recall,\n",
    "#                 \"fscore\": fscore,\n",
    "#                 \"kappa\": kappa,\n",
    "#                 \"elects_earliness\": earliness,\n",
    "#                 \"classification_loss\": classification_loss,\n",
    "#                 \"earliness_reward\": earliness_reward,\n",
    "#                 \"classification_earliness\": stats[\"classification_earliness\"],\n",
    "#                 \"harmonic_mean\": harmonic_mean,\n",
    "#                 \"boxplot\": wandb.Image(fig_boxplot),\n",
    "#                 \"conf_mat\" : wandb.plot.confusion_matrix(probs=None,\n",
    "#                         y_true=stats[\"targets\"][:,0], preds=stats[\"predictions_at_t_stop\"][:,0],\n",
    "#                         class_names=class_names, title=\"Confusion Matrix\")\n",
    "#             })\n",
    "#         plt.close(fig_boxplot)\n",
    "\n",
    "#         df = pd.DataFrame(train_stats).set_index(\"epoch\")\n",
    "\n",
    "#         savemsg = \"\"\n",
    "#         if len(df) > 2:\n",
    "#             if testloss < df.testloss[:-1].values.min():\n",
    "#                 savemsg = f\"saving model to {args.snapshot}\"\n",
    "#                 os.makedirs(os.path.dirname(args.snapshot), exist_ok=True)\n",
    "#                 torch.save(model.state_dict(), args.snapshot)\n",
    "\n",
    "#                 optimizer_snapshot = os.path.join(os.path.dirname(args.snapshot),\n",
    "#                                                     os.path.basename(args.snapshot).replace(\".pth\", \"_optimizer.pth\")\n",
    "#                                                     )\n",
    "#                 torch.save(optimizer.state_dict(), optimizer_snapshot)\n",
    "#                 wandb.log_artifact(args.snapshot, type=\"model\")  \n",
    "\n",
    "#                 df.to_csv(args.snapshot + \".csv\")\n",
    "#                 not_improved = 0 # reset early stopping counter\n",
    "#             else:\n",
    "#                 not_improved += 1 # increment early stopping counter\n",
    "#                 if args.patience is not None:\n",
    "#                     savemsg = f\"early stopping in {args.patience - not_improved} epochs.\"\n",
    "#                 else:\n",
    "#                     savemsg = \"\"\n",
    "\n",
    "#         pbar.set_description(f\"epoch {epoch}: trainloss {trainloss:.2f}, testloss {testloss:.2f}, \"\n",
    "#                      f\"accuracy {accuracy:.2f}, earliness {earliness:.2f}. \"\n",
    "#                      f\"classification loss {classification_loss:.2f}, earliness reward {earliness_reward:.2f}, harmonic mean {harmonic_mean:.2f}. {savemsg}\")\n",
    "        \n",
    "            \n",
    "#         if args.patience is not None:\n",
    "#             if not_improved > args.patience:\n",
    "#                 print(f\"stopping training. testloss {testloss:.2f} did not improve in {args.patience} epochs.\")\n",
    "#                 break\n",
    "    \n",
    "# # ----------------------------- SAVE FINAL MODEL -----------------------------\n",
    "# wandb.log_artifact(args.snapshot, type=\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff5775d3c86248afaf9a2c2575f2b816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">genial-brook-86</strong> at: <a href='https://wandb.ai/aurenore/ELECTS/runs/ljad4fw6/workspace' target=\"_blank\">https://wandb.ai/aurenore/ELECTS/runs/ljad4fw6/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240404_165004-ljad4fw6\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elects_environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
